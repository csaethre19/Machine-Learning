{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "homework1_softmax.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jordansaethre/MATH-7960-ML/blob/master/homework1_softmaxJS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qcUwZ2kYYV-q",
        "colab_type": "text"
      },
      "source": [
        "# Homework 1: Classifiers\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2fakcGhJ08N",
        "colab_type": "text"
      },
      "source": [
        "# Linear Softmax Classifier\n",
        "\n",
        "This exercise is analogous to the SVM exercise. You will:\n",
        "\n",
        "- implement a fully-vectorized **loss function** for the Softmax classifier\n",
        "- implement the fully-vectorized expression for its **analytic gradient**\n",
        "- **check your implementation** with numerical gradient\n",
        "- use a validation set to **tune the learning rate and regularization** strength\n",
        "- **optimize** the loss function with **SGD**\n",
        "- **visualize** the final learned weights\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3CGTpwFJ08P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "190f29c3-18bb-4165-eedc-21016ad5a055"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "sns.set()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGrRij4Tqdxf",
        "colab_type": "text"
      },
      "source": [
        "## Load and preprocess CIFAR-10 dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpJ-YmcDJ08S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "1a08dd4b-7537-4f5a-ae54-6e8f28bac2ea"
      },
      "source": [
        "from keras.datasets import cifar10\n",
        "\n",
        "def get_CIFAR10_data(num_training=49000, num_validation=1000,\n",
        "                     num_test=1000, num_dev=500):\n",
        "    \"\"\"\n",
        "    Load the CIFAR-10 dataset from disk and perform preprocessing to prepare\n",
        "    it for the linear classifier. These are the same steps as we used for the\n",
        "    SVM, but condensed to a single function.  \n",
        "    \"\"\"\n",
        "    # Load the raw CIFAR-10 data\n",
        "    (X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "    \n",
        "    # All the data comes in the uint8 format, so we need to convert\n",
        "    # it to floats so that we compute numbers greater than 255.\n",
        "    X_train = X_train.astype(np.float)\n",
        "    X_test = X_test.astype(np.float)\n",
        "    # Also, for convenience we flatten the class arrays.\n",
        "    y_train = y_train.flatten()\n",
        "    y_test = y_test.flatten()\n",
        "    \n",
        "    # Split the data into train, val, and test sets. In addition we will\n",
        "    # create a small development set as a subset of the training data;\n",
        "    # we can use this for development so our code runs faster.\n",
        "    \n",
        "    # Our validation set will be num_validation points from the original\n",
        "    # training set.\n",
        "    mask = list(range(num_training, num_training + num_validation))\n",
        "    X_val = X_train[mask]\n",
        "    y_val = y_train[mask]\n",
        "    \n",
        "    # Our training set will be the first num_train points from the original\n",
        "    # training set.\n",
        "    mask = list(range(num_training))\n",
        "    X_train = X_train[mask]\n",
        "    y_train = y_train[mask]\n",
        "    \n",
        "    # We will also make a development set, which is a small subset of\n",
        "    # the training set.\n",
        "    mask = np.random.choice(num_training, num_dev, replace=False)\n",
        "    X_dev = X_train[mask]\n",
        "    y_dev = y_train[mask]\n",
        "    \n",
        "    # We use the first num_test points of the original test set as our\n",
        "    # test set.\n",
        "    mask = list(range(num_test))\n",
        "    X_test = X_test[mask]\n",
        "    y_test = y_test[mask]\n",
        "    \n",
        "    # Preprocessing: reshape the image data into rows\n",
        "    X_train = np.reshape(X_train, (X_train.shape[0], -1))\n",
        "    X_val = np.reshape(X_val, (X_val.shape[0], -1))\n",
        "    X_test = np.reshape(X_test, (X_test.shape[0], -1))\n",
        "    X_dev = np.reshape(X_dev, (X_dev.shape[0], -1))\n",
        "    \n",
        "    # Normalize the data: subtract the mean image\n",
        "    mean_image = np.mean(X_train, axis = 0)\n",
        "    X_train -= mean_image\n",
        "    X_val -= mean_image\n",
        "    X_test -= mean_image\n",
        "    X_dev -= mean_image\n",
        "    \n",
        "    # third: append the bias dimension of ones (i.e. bias trick) so that our SVM\n",
        "    # only has to worry about optimizing a single weight matrix W.\n",
        "    X_train = np.hstack([X_train, np.ones((X_train.shape[0], 1))])\n",
        "    X_val = np.hstack([X_val, np.ones((X_val.shape[0], 1))])\n",
        "    X_test = np.hstack([X_test, np.ones((X_test.shape[0], 1))])\n",
        "    X_dev = np.hstack([X_dev, np.ones((X_dev.shape[0], 1))])\n",
        "    \n",
        "    return X_train, y_train, X_val, y_val, X_test, y_test, X_dev, y_dev\n",
        "\n",
        "\n",
        "# Invoke the above function to get our data.\n",
        "X_train, y_train, X_val, y_val, X_test, y_test, X_dev, y_dev = get_CIFAR10_data()\n",
        "print('Train data shape: ', X_train.shape)\n",
        "print('Train labels shape: ', y_train.shape)\n",
        "print('Validation data shape: ', X_val.shape)\n",
        "print('Validation labels shape: ', y_val.shape)\n",
        "print('Test data shape: ', X_test.shape)\n",
        "print('Test labels shape: ', y_test.shape)\n",
        "print('dev data shape: ', X_dev.shape)\n",
        "print('dev labels shape: ', y_dev.shape)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 6s 0us/step\n",
            "Train data shape:  (49000, 3073)\n",
            "Train labels shape:  (49000,)\n",
            "Validation data shape:  (1000, 3073)\n",
            "Validation labels shape:  (1000,)\n",
            "Test data shape:  (1000, 3073)\n",
            "Test labels shape:  (1000,)\n",
            "dev data shape:  (500, 3073)\n",
            "dev labels shape:  (500,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YqRGKxjJ08V",
        "colab_type": "text"
      },
      "source": [
        "## Define a naive Softmax classifier loss function\n",
        "\n",
        "Next we define the Softmax loss function.  This will be a naive implementation using loops.  Most of the code for this loss function already exists, but you will need to write code of your own to finish it.  Follow the instructions in the TODO section.\n",
        "\n",
        "Recall that the contribution of a training point $(x_i, y_i)$ to the Softmax loss function is\n",
        "\n",
        "$$L_i = -\\log \\left( \\frac{\\exp(s_{y_i})}{\\sum_{j} \\exp(s_j)} \\right)$$\n",
        "\n",
        "This is the cross-entropy between the predicted class probabilities, and the distribution with all probability concentrated at $y_i$.  The score $s$ is again parametrized by a linear function $s_j = xW_j$ where $x$ is a single data sample and $W_j$ is the $j$th column of $W$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNzBpdmbY67R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def softmax_loss_naive(W, X, y, reg):\n",
        "  \"\"\"\n",
        "  Softmax loss function, naive implementation (with loops)\n",
        "\n",
        "  Inputs have dimension D, there are C classes, and we operate on minibatches\n",
        "  of N examples.\n",
        "\n",
        "  Inputs:\n",
        "  - W: A numpy array of shape (D, C) containing weights.\n",
        "  - X: A numpy array of shape (N, D) containing a minibatch of data.\n",
        "  - y: A numpy array of shape (N,) containing training labels; y[i] = c means\n",
        "    that X[i] has label c, where 0 <= c < C.\n",
        "  - reg: (float) regularization strength\n",
        "\n",
        "  Returns a tuple of:\n",
        "  - loss as single float\n",
        "  - gradient with respect to weights W; an array of same shape as W\n",
        "  \"\"\"\n",
        "  # Initialize the loss and gradient to zero.\n",
        "  loss = 0.0\n",
        "  dW = np.zeros_like(W)\n",
        "\n",
        "  #############################################################################\n",
        "  # TODO: Compute the softmax loss and its gradient using explicit loops.     #\n",
        "  # Store the loss in loss and the gradient in dW. If you are not careful     #\n",
        "  # here, it is easy to run into numeric instability. Don't forget the        #\n",
        "  # regularization!                                                           #\n",
        "  #############################################################################\n",
        "  \n",
        "  num_classes = W.shape[1]\n",
        "  num_train = X.shape[0]\n",
        "  scores = X.dot(W)\n",
        "\n",
        "  for i in range(num_train):\n",
        "    logC = -np.max(scores[i]) # for numerical stability\n",
        "    softmax = np.exp(scores[i] + logC)/(np.sum(np.exp(scores[i] + logC)))\n",
        "    loss += -np.log(softmax[y[i]])\n",
        "    for j in range(num_classes):\n",
        "      dW[:,j] += X[i]*softmax[j]\n",
        "    dW[:,y[i]] += -X[i]\n",
        "\n",
        "  loss /= num_train\n",
        "  dW = dW/num_train\n",
        "  loss += reg * np.sum(W * W)\n",
        "  dW = dW + reg*2*W\n",
        "\n",
        "  pass\n",
        "  #############################################################################\n",
        "  #                          END OF YOUR CODE                                 #\n",
        "  #############################################################################\n",
        "\n",
        "  return loss, dW"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJPp2yuBJ08W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "77319534-cf05-4841-a90c-6d1af0802b5a"
      },
      "source": [
        "# Evaluate the naive implementation of the loss we provided for you:\n",
        "import time\n",
        "\n",
        "# Generate a random softmax weight matrix and use it to compute the loss.\n",
        "W = np.random.randn(3073, 10) * 0.0001\n",
        "loss, grad = softmax_loss_naive(W, X_dev, y_dev, 0.0)\n",
        "\n",
        "# As a rough sanity check, our loss should be something close to -log(0.1).\n",
        "print('loss: %f' % loss)\n",
        "print('sanity check: %f' % (-np.log(0.1)))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss: 2.373120\n",
            "sanity check: 2.302585\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSZOfaTpJ08Z",
        "colab_type": "text"
      },
      "source": [
        "## Inline Question 1:\n",
        "Why do we expect our loss to be close to -log(0.1)? Explain briefly.\n",
        "\n",
        "**Your answer:** \n",
        "\n",
        "*When you initially calculate the loss all classes are equally likely so -log(0.1) says that there is a 1/10 chance any one class will be chosen.*\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaIHaDRiZTP0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "c09ab107-f2ff-4e5b-d663-1d55ea8c442a"
      },
      "source": [
        "def grad_check_sparse(f, x, analytic_grad, num_checks=10, h=1e-5):\n",
        "  \"\"\"\n",
        "  sample a few random elements and only return numerical\n",
        "  in this dimensions.\n",
        "  \"\"\"\n",
        "\n",
        "  for i in range(num_checks):\n",
        "    ix = tuple([np.random.randint(m) for m in x.shape])\n",
        "\n",
        "    oldval = x[ix]\n",
        "    x[ix] = oldval + h # increment by h\n",
        "    fxph = f(x) # evaluate f(x + h)\n",
        "    x[ix] = oldval - h # increment by h\n",
        "    fxmh = f(x) # evaluate f(x - h)\n",
        "    x[ix] = oldval # reset\n",
        "\n",
        "    grad_numerical = (fxph - fxmh) / (2 * h)\n",
        "    grad_analytic = analytic_grad[ix]\n",
        "    rel_error = abs(grad_numerical - grad_analytic) / (abs(grad_numerical) + abs(grad_analytic))\n",
        "    print('numerical: %f analytic: %f, relative error: %e' % (grad_numerical, grad_analytic, rel_error))\n",
        "    \n",
        "# Complete the implementation of softmax_loss_naive and implement a (naive)\n",
        "# version of the gradient that uses nested loops.\n",
        "loss, grad = softmax_loss_naive(W, X_dev, y_dev, 0.0)\n",
        "\n",
        "# As we did for the SVM, use numeric gradient checking as a debugging tool.\n",
        "# The numeric gradient should be close to the analytic gradient.\n",
        "f = lambda w: softmax_loss_naive(w, X_dev, y_dev, 0.0)[0]\n",
        "grad_numerical = grad_check_sparse(f, W, grad, 10)\n",
        "\n",
        "# similar to SVM case, do another gradient check with regularization\n",
        "loss, grad = softmax_loss_naive(W, X_dev, y_dev, 5e1)\n",
        "f = lambda w: softmax_loss_naive(w, X_dev, y_dev, 5e1)[0]\n",
        "grad_numerical = grad_check_sparse(f, W, grad, 10)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "numerical: -1.330625 analytic: -1.330625, relative error: 8.654615e-09\n",
            "numerical: 0.026079 analytic: 0.026079, relative error: 1.450905e-06\n",
            "numerical: 4.309576 analytic: 4.309576, relative error: 1.493627e-08\n",
            "numerical: -2.551538 analytic: -2.551538, relative error: 6.946413e-09\n",
            "numerical: 1.099748 analytic: 1.099748, relative error: 6.680991e-08\n",
            "numerical: -0.791373 analytic: -0.791373, relative error: 4.695086e-08\n",
            "numerical: -0.027072 analytic: -0.027072, relative error: 9.955351e-07\n",
            "numerical: 0.212155 analytic: 0.212155, relative error: 3.110751e-07\n",
            "numerical: 1.088516 analytic: 1.088516, relative error: 4.364669e-08\n",
            "numerical: 0.289100 analytic: 0.289100, relative error: 3.151589e-07\n",
            "numerical: 0.737700 analytic: 0.737700, relative error: 8.777556e-08\n",
            "numerical: 1.861027 analytic: 1.861027, relative error: 4.364654e-08\n",
            "numerical: 1.206857 analytic: 1.206857, relative error: 3.786341e-08\n",
            "numerical: -2.935525 analytic: -2.935525, relative error: 3.990055e-09\n",
            "numerical: -0.340106 analytic: -0.340106, relative error: 9.855703e-08\n",
            "numerical: 2.137772 analytic: 2.137772, relative error: 4.661864e-08\n",
            "numerical: 0.778106 analytic: 0.778106, relative error: 9.315524e-09\n",
            "numerical: 1.674345 analytic: 1.674345, relative error: 2.962116e-08\n",
            "numerical: 0.090696 analytic: 0.090696, relative error: 4.125479e-07\n",
            "numerical: 1.491727 analytic: 1.491727, relative error: 2.578445e-08\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AW-ddDOCsXMW",
        "colab_type": "text"
      },
      "source": [
        "## Define a vectorized Softmax classifier loss function\n",
        "\n",
        "Next we define the vectorized (i.e. no loops) version of the Softmax loss function.  Most of the code for this loss function already exists, but you will need to write code of your own to finish it.  Follow the instructions in the TODO section."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2HDgzaMZfRV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def softmax_loss_vectorized(W, X, y, reg):\n",
        "  \"\"\"\n",
        "  Softmax loss function, vectorized version.\n",
        "\n",
        "  Inputs and outputs are the same as softmax_loss_naive.\n",
        "  \"\"\"\n",
        "  # Initialize the loss and gradient to zero.\n",
        "  loss = 0.0\n",
        "  dW = np.zeros_like(W)\n",
        "\n",
        "  #############################################################################\n",
        "  # TODO: Compute the softmax loss and its gradient using no explicit loops.  #\n",
        "  # Store the loss in loss and the gradient in dW. If you are not careful     #\n",
        "  # here, it is easy to run into numeric instability. Don't forget the        #\n",
        "  # regularization!                                                           #\n",
        "  #############################################################################\n",
        "\n",
        "  num_classes = W.shape[1]\n",
        "  num_train = X.shape[0]\n",
        "  correct_class_score_indices =[np.arange(num_train),y]\n",
        "\n",
        "  scores = X.dot(W)\n",
        "  logC = -np.max(scores, axis = 1, keepdims = True)\n",
        "  scores += logC\n",
        "  exp_scores = np.exp(scores)\n",
        "  sum_exp_scores = np.sum(exp_scores, axis = 1, keepdims = True)\n",
        "  softmax = exp_scores/sum_exp_scores\n",
        "  log_softmax = -np.log(softmax[correct_class_score_indices])\n",
        "  loss = np.sum(log_softmax)\n",
        "  loss /= num_train\n",
        "  loss += reg * np.sum(W * W)\n",
        "\n",
        "  XT = np.transpose(X)\n",
        "  softmax[correct_class_score_indices] -= 1\n",
        "  dW = XT.dot(softmax)\n",
        "  dW = dW/num_train\n",
        "  dW = dW + reg*2*W\n",
        "\n",
        "  pass\n",
        "  #############################################################################\n",
        "  #                          END OF YOUR CODE                                 #\n",
        "  #############################################################################\n",
        "\n",
        "  return loss, dW"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSxdTSBPJ08d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "c41361d0-021b-4fcd-98bb-d6b5843858c0"
      },
      "source": [
        "# Evaluate the naive implementation of the Softmax gradients\n",
        "\n",
        "# The naive implementation and the vectorized implementation should match, but\n",
        "# the vectorized version should still be much faster.\n",
        "tic = time.time()\n",
        "loss_naive, grad_naive = softmax_loss_naive(W, X_dev, y_dev, 0.000005)\n",
        "toc = time.time()\n",
        "print('naive loss: %e computed in %fs' % (loss_naive, toc - tic))\n",
        "\n",
        "tic = time.time()\n",
        "loss_vectorized, grad_vectorized = softmax_loss_vectorized(W, X_dev, y_dev, 0.000005)\n",
        "toc = time.time()\n",
        "print('vectorized loss: %e computed in %fs' % (loss_vectorized, toc - tic))\n",
        "\n",
        "# As we did for the SVM, we use the Frobenius norm to compare the two versions\n",
        "# of the gradient.\n",
        "grad_difference = np.linalg.norm(grad_naive - grad_vectorized, ord='fro')\n",
        "print('Loss difference: %f' % np.abs(loss_naive - loss_vectorized))\n",
        "print('Gradient difference: %f' % grad_difference)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "naive loss: 2.373120e+00 computed in 0.123671s\n",
            "vectorized loss: 2.373120e+00 computed in 0.008686s\n",
            "Loss difference: 0.000000\n",
            "Gradient difference: 0.000000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:28: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:34: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6zzNjOgtYDq",
        "colab_type": "text"
      },
      "source": [
        "## Stochastic Gradient Descent\n",
        "\n",
        "We now have vectorized and efficient expressions for the loss, the gradient and our gradient matches the numerical gradient. We are therefore ready to do SGD to minimize the loss. Follow the instructions in the TODO sections below.  You may just want to copy the code you wrote for the SVM."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRZYRkF7ZzE0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Softmax(object):\n",
        "\n",
        "  def __init__(self):\n",
        "    self.W = None\n",
        "\n",
        "  def train(self, X, y, learning_rate=1e-3, reg=1e-5, num_iters=100,\n",
        "            batch_size=200, verbose=False):\n",
        "    \"\"\"\n",
        "    Train this linear classifier using stochastic gradient descent.\n",
        "\n",
        "    Inputs:\n",
        "    - X: A numpy array of shape (N, D) containing training data; there are N\n",
        "      training samples each of dimension D.\n",
        "    - y: A numpy array of shape (N,) containing training labels; y[i] = c\n",
        "      means that X[i] has label 0 <= c < C for C classes.\n",
        "    - learning_rate: (float) learning rate for optimization.\n",
        "    - reg: (float) regularization strength.\n",
        "    - num_iters: (integer) number of steps to take when optimizing\n",
        "    - batch_size: (integer) number of training examples to use at each step.\n",
        "    - verbose: (boolean) If true, print progress during optimization.\n",
        "\n",
        "    Outputs:\n",
        "    A list containing the value of the loss function at each training iteration.\n",
        "    \"\"\"\n",
        "    num_train, dim = X.shape\n",
        "    num_classes = np.max(y) + 1 # assume y takes values 0...K-1 where K is number of classes\n",
        "    if self.W is None:\n",
        "      # lazily initialize W\n",
        "      self.W = 0.001 * np.random.randn(dim, num_classes)\n",
        "\n",
        "    # Run stochastic gradient descent to optimize W\n",
        "    loss_history = []\n",
        "    for it in range(num_iters):\n",
        "      X_batch = None\n",
        "      y_batch = None\n",
        "\n",
        "      #########################################################################\n",
        "      # TODO:                                                                 #\n",
        "      # Sample batch_size elements from the training data and their           #\n",
        "      # corresponding labels to use in this round of gradient descent.        #\n",
        "      # Store the data in X_batch and their corresponding labels in           #\n",
        "      # y_batch; after sampling X_batch should have shape (dim, batch_size)   #\n",
        "      # and y_batch should have shape (batch_size,)                           #\n",
        "      #                                                                       #\n",
        "      # Hint: Use np.random.choice to generate indices. Sampling with         #\n",
        "      # replacement is faster than sampling without replacement.              #\n",
        "      #########################################################################\n",
        "\n",
        "      batch_indices = np.random.choice(num_train, batch_size, replace=True)\n",
        "      X_batch = X[batch_indices]\n",
        "      y_batch = y[batch_indices]\n",
        "\n",
        "      pass\n",
        "      #########################################################################\n",
        "      #                       END OF YOUR CODE                                #\n",
        "      #########################################################################\n",
        "\n",
        "      # evaluate loss and gradient\n",
        "      loss, grad = self.loss(X_batch, y_batch, reg)\n",
        "      loss_history.append(loss)\n",
        "\n",
        "      # perform parameter update\n",
        "      #########################################################################\n",
        "      # TODO:                                                                 #\n",
        "      # Update the weights using the gradient and the learning rate.          #\n",
        "      #########################################################################\n",
        "\n",
        "      self.W -= learning_rate*grad\n",
        "\n",
        "      pass\n",
        "      #########################################################################\n",
        "      #                       END OF YOUR CODE                                #\n",
        "      #########################################################################\n",
        "\n",
        "      if verbose and it % 100 == 0:\n",
        "        print('iteration %d / %d: loss %f' % (it, num_iters, loss))\n",
        "\n",
        "    return loss_history\n",
        "\n",
        "  def predict(self, X):\n",
        "    \"\"\"\n",
        "    Use the trained weights of this linear classifier to predict labels for\n",
        "    data points.\n",
        "\n",
        "    Inputs:\n",
        "    - X: A numpy array of shape (N, D) containing training data; there are N\n",
        "      training samples each of dimension D.\n",
        "\n",
        "    Returns:\n",
        "    - y_pred: Predicted labels for the data in X. y_pred is a 1-dimensional\n",
        "      array of length N, and each element is an integer giving the predicted\n",
        "      class.\n",
        "    \"\"\"\n",
        "    y_pred = np.zeros(X.shape[0])\n",
        "    ###########################################################################\n",
        "    # TODO:                                                                   #\n",
        "    # Implement this method. Store the predicted labels in y_pred.            #\n",
        "    ###########################################################################\n",
        "\n",
        "    scores = X.dot(self.W)\n",
        "    y_pred = np.argmax(scores, axis = 1)\n",
        "    \n",
        "    pass\n",
        "    ###########################################################################\n",
        "    #                           END OF YOUR CODE                              #\n",
        "    ###########################################################################\n",
        "    return y_pred\n",
        "  \n",
        "  def loss(self, X_batch, y_batch, reg):\n",
        "    \"\"\"\n",
        "    Compute the loss function and its derivative. \n",
        "    Subclasses will override this.\n",
        "\n",
        "    Inputs:\n",
        "    - X_batch: A numpy array of shape (N, D) containing a minibatch of N\n",
        "      data points; each point has dimension D.\n",
        "    - y_batch: A numpy array of shape (N,) containing labels for the minibatch.\n",
        "    - reg: (float) regularization strength.\n",
        "\n",
        "    Returns: A tuple containing:\n",
        "    - loss as a single float\n",
        "    - gradient with respect to self.W; an array of the same shape as W\n",
        "    \"\"\"\n",
        "    return softmax_loss_vectorized(self.W, X_batch, y_batch, reg)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOKw3bKKJ08f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1b83f5a5-ba0e-4642-868a-7d4fa255f0bc"
      },
      "source": [
        "# Use the validation set to tune hyperparameters (regularization strength and\n",
        "# learning rate). You should experiment with different ranges for the learning\n",
        "# rates and regularization strengths; if you are careful you should be able to\n",
        "# get a classification accuracy of over 0.35 on the validation set.\n",
        "results = {}\n",
        "best_val = -1\n",
        "best_softmax = None\n",
        "learning_rates = [1e-7, 1e-6, 1e-5,5e-7, 5e-6,5e-5]\n",
        "regularization_strengths = [2.5e4, 5e4, 7.5e4, 10e4, 12.5e4, 15e4]\n",
        "\n",
        "################################################################################\n",
        "# TODO:                                                                        #\n",
        "# Use the validation set to set the learning rate and regularization strength. #\n",
        "# This should be identical to the validation that you did for the SVM; save    #\n",
        "# the best trained softmax classifer in best_softmax.                          #\n",
        "################################################################################\n",
        "\n",
        "from itertools import product \n",
        "\n",
        "hyperparams = list(product(learning_rates,regularization_strengths))\n",
        "\n",
        "for combo in hyperparams:\n",
        "  softmax_classifer = Softmax()\n",
        "\n",
        "  train_loss = softmax_classifer.train(X_train, y_train,\n",
        "                         learning_rate=combo[0],\n",
        "                         reg=combo[1],\n",
        "                         num_iters=1500,\n",
        "                         verbose=True)\n",
        "  \n",
        "  y_train_pred = softmax_classifer.predict(X_train)\n",
        "  y_val_pred = softmax_classifer.predict(X_val)\n",
        "\n",
        "  train_acc = np.mean(y_train == y_train_pred)\n",
        "  val_acc = np.mean(y_val == y_val_pred)\n",
        "\n",
        "  results[combo] = (train_acc, val_acc)\n",
        "\n",
        "  if best_val < val_acc:\n",
        "    best_val = val_acc\n",
        "    best_softmax_classifer = softmax_classifer\n",
        "\n",
        "pass\n",
        "################################################################################\n",
        "#                              END OF YOUR CODE                                #\n",
        "################################################################################\n",
        "    \n",
        "# Print out results.\n",
        "for lr, reg in sorted(results):\n",
        "    train_accuracy, val_accuracy = results[(lr, reg)]\n",
        "    print('lr %e reg %e train accuracy: %f val accuracy: %f' % (\n",
        "                lr, reg, train_accuracy, val_accuracy))\n",
        "    \n",
        "print('best validation accuracy achieved during cross-validation: %f' % best_val)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:28: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:34: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "iteration 0 / 1500: loss 774.045126\n",
            "iteration 100 / 1500: loss 284.057655\n",
            "iteration 200 / 1500: loss 105.216534\n",
            "iteration 300 / 1500: loss 39.753558\n",
            "iteration 400 / 1500: loss 15.865346\n",
            "iteration 500 / 1500: loss 7.100259\n",
            "iteration 600 / 1500: loss 4.016420\n",
            "iteration 700 / 1500: loss 2.823682\n",
            "iteration 800 / 1500: loss 2.370396\n",
            "iteration 900 / 1500: loss 2.174135\n",
            "iteration 1000 / 1500: loss 2.138870\n",
            "iteration 1100 / 1500: loss 2.093696\n",
            "iteration 1200 / 1500: loss 2.068046\n",
            "iteration 1300 / 1500: loss 2.079203\n",
            "iteration 1400 / 1500: loss 2.122930\n",
            "iteration 0 / 1500: loss 1550.420194\n",
            "iteration 100 / 1500: loss 208.667769\n",
            "iteration 200 / 1500: loss 29.736702\n",
            "iteration 300 / 1500: loss 5.817097\n",
            "iteration 400 / 1500: loss 2.644027\n",
            "iteration 500 / 1500: loss 2.182874\n",
            "iteration 600 / 1500: loss 2.190456\n",
            "iteration 700 / 1500: loss 2.199067\n",
            "iteration 800 / 1500: loss 2.185317\n",
            "iteration 900 / 1500: loss 2.123425\n",
            "iteration 1000 / 1500: loss 2.189422\n",
            "iteration 1100 / 1500: loss 2.106887\n",
            "iteration 1200 / 1500: loss 2.163767\n",
            "iteration 1300 / 1500: loss 2.121364\n",
            "iteration 1400 / 1500: loss 2.154806\n",
            "iteration 0 / 1500: loss 2311.647204\n",
            "iteration 100 / 1500: loss 114.072452\n",
            "iteration 200 / 1500: loss 7.613429\n",
            "iteration 300 / 1500: loss 2.438108\n",
            "iteration 400 / 1500: loss 2.203010\n",
            "iteration 500 / 1500: loss 2.134798\n",
            "iteration 600 / 1500: loss 2.167195\n",
            "iteration 700 / 1500: loss 2.148048\n",
            "iteration 800 / 1500: loss 2.097082\n",
            "iteration 900 / 1500: loss 2.198778\n",
            "iteration 1000 / 1500: loss 2.141509\n",
            "iteration 1100 / 1500: loss 2.172002\n",
            "iteration 1200 / 1500: loss 2.154906\n",
            "iteration 1300 / 1500: loss 2.191379\n",
            "iteration 1400 / 1500: loss 2.207956\n",
            "iteration 0 / 1500: loss 3085.500181\n",
            "iteration 100 / 1500: loss 56.257922\n",
            "iteration 200 / 1500: loss 3.135707\n",
            "iteration 300 / 1500: loss 2.225824\n",
            "iteration 400 / 1500: loss 2.206852\n",
            "iteration 500 / 1500: loss 2.189629\n",
            "iteration 600 / 1500: loss 2.167082\n",
            "iteration 700 / 1500: loss 2.230094\n",
            "iteration 800 / 1500: loss 2.205338\n",
            "iteration 900 / 1500: loss 2.187260\n",
            "iteration 1000 / 1500: loss 2.195055\n",
            "iteration 1100 / 1500: loss 2.187486\n",
            "iteration 1200 / 1500: loss 2.181041\n",
            "iteration 1300 / 1500: loss 2.171918\n",
            "iteration 1400 / 1500: loss 2.194031\n",
            "iteration 0 / 1500: loss 3822.748272\n",
            "iteration 100 / 1500: loss 26.255807\n",
            "iteration 200 / 1500: loss 2.352741\n",
            "iteration 300 / 1500: loss 2.184663\n",
            "iteration 400 / 1500: loss 2.202695\n",
            "iteration 500 / 1500: loss 2.202279\n",
            "iteration 600 / 1500: loss 2.219788\n",
            "iteration 700 / 1500: loss 2.208689\n",
            "iteration 800 / 1500: loss 2.212803\n",
            "iteration 900 / 1500: loss 2.242855\n",
            "iteration 1000 / 1500: loss 2.182534\n",
            "iteration 1100 / 1500: loss 2.210374\n",
            "iteration 1200 / 1500: loss 2.215482\n",
            "iteration 1300 / 1500: loss 2.201135\n",
            "iteration 1400 / 1500: loss 2.180070\n",
            "iteration 0 / 1500: loss 4624.090176\n",
            "iteration 100 / 1500: loss 12.620884\n",
            "iteration 200 / 1500: loss 2.237784\n",
            "iteration 300 / 1500: loss 2.192150\n",
            "iteration 400 / 1500: loss 2.203373\n",
            "iteration 500 / 1500: loss 2.224401\n",
            "iteration 600 / 1500: loss 2.218848\n",
            "iteration 700 / 1500: loss 2.221421\n",
            "iteration 800 / 1500: loss 2.207953\n",
            "iteration 900 / 1500: loss 2.220934\n",
            "iteration 1000 / 1500: loss 2.220299\n",
            "iteration 1100 / 1500: loss 2.230018\n",
            "iteration 1200 / 1500: loss 2.225004\n",
            "iteration 1300 / 1500: loss 2.192516\n",
            "iteration 1400 / 1500: loss 2.222317\n",
            "iteration 0 / 1500: loss 771.285525\n",
            "iteration 100 / 1500: loss 2.114433\n",
            "iteration 200 / 1500: loss 2.090794\n",
            "iteration 300 / 1500: loss 2.152112\n",
            "iteration 400 / 1500: loss 2.064772\n",
            "iteration 500 / 1500: loss 2.052373\n",
            "iteration 600 / 1500: loss 2.156701\n",
            "iteration 700 / 1500: loss 2.080846\n",
            "iteration 800 / 1500: loss 2.108754\n",
            "iteration 900 / 1500: loss 2.108233\n",
            "iteration 1000 / 1500: loss 2.117684\n",
            "iteration 1100 / 1500: loss 2.150194\n",
            "iteration 1200 / 1500: loss 2.130202\n",
            "iteration 1300 / 1500: loss 2.052924\n",
            "iteration 1400 / 1500: loss 2.109415\n",
            "iteration 0 / 1500: loss 1543.676622\n",
            "iteration 100 / 1500: loss 2.151863\n",
            "iteration 200 / 1500: loss 2.146994\n",
            "iteration 300 / 1500: loss 2.148667\n",
            "iteration 400 / 1500: loss 2.152660\n",
            "iteration 500 / 1500: loss 2.139305\n",
            "iteration 600 / 1500: loss 2.151905\n",
            "iteration 700 / 1500: loss 2.175545\n",
            "iteration 800 / 1500: loss 2.175241\n",
            "iteration 900 / 1500: loss 2.141121\n",
            "iteration 1000 / 1500: loss 2.160830\n",
            "iteration 1100 / 1500: loss 2.135395\n",
            "iteration 1200 / 1500: loss 2.174669\n",
            "iteration 1300 / 1500: loss 2.148210\n",
            "iteration 1400 / 1500: loss 2.203718\n",
            "iteration 0 / 1500: loss 2324.546167\n",
            "iteration 100 / 1500: loss 2.182350\n",
            "iteration 200 / 1500: loss 2.199653\n",
            "iteration 300 / 1500: loss 2.178711\n",
            "iteration 400 / 1500: loss 2.160544\n",
            "iteration 500 / 1500: loss 2.187587\n",
            "iteration 600 / 1500: loss 2.174704\n",
            "iteration 700 / 1500: loss 2.178065\n",
            "iteration 800 / 1500: loss 2.211218\n",
            "iteration 900 / 1500: loss 2.201434\n",
            "iteration 1000 / 1500: loss 2.172477\n",
            "iteration 1100 / 1500: loss 2.228183\n",
            "iteration 1200 / 1500: loss 2.174292\n",
            "iteration 1300 / 1500: loss 2.166912\n",
            "iteration 1400 / 1500: loss 2.182427\n",
            "iteration 0 / 1500: loss 3031.041784\n",
            "iteration 100 / 1500: loss 2.189695\n",
            "iteration 200 / 1500: loss 2.221414\n",
            "iteration 300 / 1500: loss 2.217196\n",
            "iteration 400 / 1500: loss 2.215519\n",
            "iteration 500 / 1500: loss 2.221324\n",
            "iteration 600 / 1500: loss 2.221768\n",
            "iteration 700 / 1500: loss 2.205684\n",
            "iteration 800 / 1500: loss 2.189845\n",
            "iteration 900 / 1500: loss 2.215080\n",
            "iteration 1000 / 1500: loss 2.206219\n",
            "iteration 1100 / 1500: loss 2.225171\n",
            "iteration 1200 / 1500: loss 2.198149\n",
            "iteration 1300 / 1500: loss 2.208751\n",
            "iteration 1400 / 1500: loss 2.208301\n",
            "iteration 0 / 1500: loss 3881.036602\n",
            "iteration 100 / 1500: loss 2.230066\n",
            "iteration 200 / 1500: loss 2.207340\n",
            "iteration 300 / 1500: loss 2.220508\n",
            "iteration 400 / 1500: loss 2.235361\n",
            "iteration 500 / 1500: loss 2.241457\n",
            "iteration 600 / 1500: loss 2.239056\n",
            "iteration 700 / 1500: loss 2.218535\n",
            "iteration 800 / 1500: loss 2.207635\n",
            "iteration 900 / 1500: loss 2.246414\n",
            "iteration 1000 / 1500: loss 2.252112\n",
            "iteration 1100 / 1500: loss 2.220023\n",
            "iteration 1200 / 1500: loss 2.237743\n",
            "iteration 1300 / 1500: loss 2.198921\n",
            "iteration 1400 / 1500: loss 2.200170\n",
            "iteration 0 / 1500: loss 4639.927603\n",
            "iteration 100 / 1500: loss 2.239088\n",
            "iteration 200 / 1500: loss 2.248022\n",
            "iteration 300 / 1500: loss 2.229870\n",
            "iteration 400 / 1500: loss 2.255762\n",
            "iteration 500 / 1500: loss 2.223981\n",
            "iteration 600 / 1500: loss 2.229922\n",
            "iteration 700 / 1500: loss 2.222088\n",
            "iteration 800 / 1500: loss 2.249443\n",
            "iteration 900 / 1500: loss 2.262723\n",
            "iteration 1000 / 1500: loss 2.252363\n",
            "iteration 1100 / 1500: loss 2.239967\n",
            "iteration 1200 / 1500: loss 2.217928\n",
            "iteration 1300 / 1500: loss 2.224092\n",
            "iteration 1400 / 1500: loss 2.220840\n",
            "iteration 0 / 1500: loss 776.322617\n",
            "iteration 100 / 1500: loss 7.726494\n",
            "iteration 200 / 1500: loss 6.772649\n",
            "iteration 300 / 1500: loss 6.855167\n",
            "iteration 400 / 1500: loss 6.906950\n",
            "iteration 500 / 1500: loss 6.342178\n",
            "iteration 600 / 1500: loss 8.181167\n",
            "iteration 700 / 1500: loss 9.599889\n",
            "iteration 800 / 1500: loss 8.051110\n",
            "iteration 900 / 1500: loss 6.407976\n",
            "iteration 1000 / 1500: loss 8.737639\n",
            "iteration 1100 / 1500: loss 7.690785\n",
            "iteration 1200 / 1500: loss 5.587884\n",
            "iteration 1300 / 1500: loss 11.387807\n",
            "iteration 1400 / 1500: loss 9.081850\n",
            "iteration 0 / 1500: loss 1549.213097\n",
            "iteration 100 / 1500: loss 18.243962\n",
            "iteration 200 / 1500: loss 14.520697\n",
            "iteration 300 / 1500: loss 18.859222\n",
            "iteration 400 / 1500: loss 17.283776\n",
            "iteration 500 / 1500: loss 17.592313\n",
            "iteration 600 / 1500: loss 18.132351\n",
            "iteration 700 / 1500: loss 16.360907\n",
            "iteration 800 / 1500: loss 16.742000\n",
            "iteration 900 / 1500: loss 16.607677\n",
            "iteration 1000 / 1500: loss 17.178583\n",
            "iteration 1100 / 1500: loss 16.964181\n",
            "iteration 1200 / 1500: loss 17.571813\n",
            "iteration 1300 / 1500: loss 16.509584\n",
            "iteration 1400 / 1500: loss 18.318508\n",
            "iteration 0 / 1500: loss 2322.022625\n",
            "iteration 100 / 1500: loss 60.644071\n",
            "iteration 200 / 1500: loss 63.236244\n",
            "iteration 300 / 1500: loss 60.720103\n",
            "iteration 400 / 1500: loss 59.760144\n",
            "iteration 500 / 1500: loss 64.014273\n",
            "iteration 600 / 1500: loss 60.521800\n",
            "iteration 700 / 1500: loss 54.493863\n",
            "iteration 800 / 1500: loss 63.801509\n",
            "iteration 900 / 1500: loss 62.834772\n",
            "iteration 1000 / 1500: loss 56.549296\n",
            "iteration 1100 / 1500: loss 56.850801\n",
            "iteration 1200 / 1500: loss 63.603267\n",
            "iteration 1300 / 1500: loss 59.327795\n",
            "iteration 1400 / 1500: loss 60.650449\n",
            "iteration 0 / 1500: loss 3044.063429\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:28: RuntimeWarning: divide by zero encountered in log\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "iteration 100 / 1500: loss inf\n",
            "iteration 200 / 1500: loss inf\n",
            "iteration 300 / 1500: loss inf\n",
            "iteration 400 / 1500: loss inf\n",
            "iteration 500 / 1500: loss inf\n",
            "iteration 600 / 1500: loss inf\n",
            "iteration 700 / 1500: loss inf\n",
            "iteration 800 / 1500: loss inf\n",
            "iteration 900 / 1500: loss inf\n",
            "iteration 1000 / 1500: loss inf\n",
            "iteration 1100 / 1500: loss inf\n",
            "iteration 1200 / 1500: loss inf\n",
            "iteration 1300 / 1500: loss inf\n",
            "iteration 1400 / 1500: loss inf\n",
            "iteration 0 / 1500: loss 3816.897971\n",
            "iteration 100 / 1500: loss inf\n",
            "iteration 200 / 1500: loss inf\n",
            "iteration 300 / 1500: loss inf\n",
            "iteration 400 / 1500: loss inf\n",
            "iteration 500 / 1500: loss inf\n",
            "iteration 600 / 1500: loss inf\n",
            "iteration 700 / 1500: loss inf\n",
            "iteration 800 / 1500: loss inf\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:31: RuntimeWarning: overflow encountered in double_scalars\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py:90: RuntimeWarning: overflow encountered in reduce\n",
            "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:31: RuntimeWarning: overflow encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "iteration 900 / 1500: loss inf\n",
            "iteration 1000 / 1500: loss inf\n",
            "iteration 1100 / 1500: loss inf\n",
            "iteration 1200 / 1500: loss inf\n",
            "iteration 1300 / 1500: loss inf\n",
            "iteration 1400 / 1500: loss inf\n",
            "iteration 0 / 1500: loss 4545.463486\n",
            "iteration 100 / 1500: loss inf\n",
            "iteration 200 / 1500: loss inf\n",
            "iteration 300 / 1500: loss inf\n",
            "iteration 400 / 1500: loss inf\n",
            "iteration 500 / 1500: loss inf\n",
            "iteration 600 / 1500: loss inf\n",
            "iteration 700 / 1500: loss inf\n",
            "iteration 800 / 1500: loss inf\n",
            "iteration 900 / 1500: loss inf\n",
            "iteration 1000 / 1500: loss inf\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: overflow encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "iteration 1100 / 1500: loss nan\n",
            "iteration 1200 / 1500: loss nan\n",
            "iteration 1300 / 1500: loss nan\n",
            "iteration 1400 / 1500: loss nan\n",
            "iteration 0 / 1500: loss 767.888730\n",
            "iteration 100 / 1500: loss 6.904127\n",
            "iteration 200 / 1500: loss 2.042247\n",
            "iteration 300 / 1500: loss 2.091889\n",
            "iteration 400 / 1500: loss 2.102299\n",
            "iteration 500 / 1500: loss 2.102181\n",
            "iteration 600 / 1500: loss 2.091864\n",
            "iteration 700 / 1500: loss 2.156940\n",
            "iteration 800 / 1500: loss 2.105638\n",
            "iteration 900 / 1500: loss 2.147210\n",
            "iteration 1000 / 1500: loss 2.167686\n",
            "iteration 1100 / 1500: loss 2.067818\n",
            "iteration 1200 / 1500: loss 2.108012\n",
            "iteration 1300 / 1500: loss 2.064872\n",
            "iteration 1400 / 1500: loss 2.079184\n",
            "iteration 0 / 1500: loss 1525.001874\n",
            "iteration 100 / 1500: loss 2.174381\n",
            "iteration 200 / 1500: loss 2.187535\n",
            "iteration 300 / 1500: loss 2.163477\n",
            "iteration 400 / 1500: loss 2.142800\n",
            "iteration 500 / 1500: loss 2.147375\n",
            "iteration 600 / 1500: loss 2.074316\n",
            "iteration 700 / 1500: loss 2.167788\n",
            "iteration 800 / 1500: loss 2.214907\n",
            "iteration 900 / 1500: loss 2.159728\n",
            "iteration 1000 / 1500: loss 2.190875\n",
            "iteration 1100 / 1500: loss 2.130218\n",
            "iteration 1200 / 1500: loss 2.155932\n",
            "iteration 1300 / 1500: loss 2.135988\n",
            "iteration 1400 / 1500: loss 2.188345\n",
            "iteration 0 / 1500: loss 2321.783236\n",
            "iteration 100 / 1500: loss 2.164721\n",
            "iteration 200 / 1500: loss 2.176629\n",
            "iteration 300 / 1500: loss 2.190801\n",
            "iteration 400 / 1500: loss 2.165451\n",
            "iteration 500 / 1500: loss 2.176197\n",
            "iteration 600 / 1500: loss 2.146995\n",
            "iteration 700 / 1500: loss 2.170395\n",
            "iteration 800 / 1500: loss 2.165153\n",
            "iteration 900 / 1500: loss 2.164919\n",
            "iteration 1000 / 1500: loss 2.125532\n",
            "iteration 1100 / 1500: loss 2.196667\n",
            "iteration 1200 / 1500: loss 2.186702\n",
            "iteration 1300 / 1500: loss 2.150714\n",
            "iteration 1400 / 1500: loss 2.186976\n",
            "iteration 0 / 1500: loss 3074.866974\n",
            "iteration 100 / 1500: loss 2.206706\n",
            "iteration 200 / 1500: loss 2.174595\n",
            "iteration 300 / 1500: loss 2.214672\n",
            "iteration 400 / 1500: loss 2.190175\n",
            "iteration 500 / 1500: loss 2.220505\n",
            "iteration 600 / 1500: loss 2.179563\n",
            "iteration 700 / 1500: loss 2.194794\n",
            "iteration 800 / 1500: loss 2.240318\n",
            "iteration 900 / 1500: loss 2.212788\n",
            "iteration 1000 / 1500: loss 2.196550\n",
            "iteration 1100 / 1500: loss 2.204660\n",
            "iteration 1200 / 1500: loss 2.225463\n",
            "iteration 1300 / 1500: loss 2.196251\n",
            "iteration 1400 / 1500: loss 2.190635\n",
            "iteration 0 / 1500: loss 3865.932433\n",
            "iteration 100 / 1500: loss 2.207504\n",
            "iteration 200 / 1500: loss 2.225614\n",
            "iteration 300 / 1500: loss 2.219017\n",
            "iteration 400 / 1500: loss 2.202790\n",
            "iteration 500 / 1500: loss 2.253675\n",
            "iteration 600 / 1500: loss 2.207123\n",
            "iteration 700 / 1500: loss 2.233245\n",
            "iteration 800 / 1500: loss 2.222740\n",
            "iteration 900 / 1500: loss 2.190392\n",
            "iteration 1000 / 1500: loss 2.209013\n",
            "iteration 1100 / 1500: loss 2.221343\n",
            "iteration 1200 / 1500: loss 2.250061\n",
            "iteration 1300 / 1500: loss 2.192056\n",
            "iteration 1400 / 1500: loss 2.199423\n",
            "iteration 0 / 1500: loss 4607.064665\n",
            "iteration 100 / 1500: loss 2.216843\n",
            "iteration 200 / 1500: loss 2.253684\n",
            "iteration 300 / 1500: loss 2.235950\n",
            "iteration 400 / 1500: loss 2.196501\n",
            "iteration 500 / 1500: loss 2.211044\n",
            "iteration 600 / 1500: loss 2.249313\n",
            "iteration 700 / 1500: loss 2.230654\n",
            "iteration 800 / 1500: loss 2.214871\n",
            "iteration 900 / 1500: loss 2.223824\n",
            "iteration 1000 / 1500: loss 2.229313\n",
            "iteration 1100 / 1500: loss 2.224805\n",
            "iteration 1200 / 1500: loss 2.220605\n",
            "iteration 1300 / 1500: loss 2.209792\n",
            "iteration 1400 / 1500: loss 2.234328\n",
            "iteration 0 / 1500: loss 772.186057\n",
            "iteration 100 / 1500: loss 2.732088\n",
            "iteration 200 / 1500: loss 2.873685\n",
            "iteration 300 / 1500: loss 2.366848\n",
            "iteration 400 / 1500: loss 2.945887\n",
            "iteration 500 / 1500: loss 2.683279\n",
            "iteration 600 / 1500: loss 2.791937\n",
            "iteration 700 / 1500: loss 2.334098\n",
            "iteration 800 / 1500: loss 2.173403\n",
            "iteration 900 / 1500: loss 3.391441\n",
            "iteration 1000 / 1500: loss 2.730478\n",
            "iteration 1100 / 1500: loss 2.649275\n",
            "iteration 1200 / 1500: loss 2.463060\n",
            "iteration 1300 / 1500: loss 3.157439\n",
            "iteration 1400 / 1500: loss 2.655244\n",
            "iteration 0 / 1500: loss 1559.011933\n",
            "iteration 100 / 1500: loss 3.811564\n",
            "iteration 200 / 1500: loss 3.452792\n",
            "iteration 300 / 1500: loss 3.614482\n",
            "iteration 400 / 1500: loss 3.170536\n",
            "iteration 500 / 1500: loss 3.952693\n",
            "iteration 600 / 1500: loss 3.311559\n",
            "iteration 700 / 1500: loss 4.391773\n",
            "iteration 800 / 1500: loss 3.743499\n",
            "iteration 900 / 1500: loss 2.796709\n",
            "iteration 1000 / 1500: loss 3.077319\n",
            "iteration 1100 / 1500: loss 3.626138\n",
            "iteration 1200 / 1500: loss 3.306499\n",
            "iteration 1300 / 1500: loss 2.819124\n",
            "iteration 1400 / 1500: loss 3.811551\n",
            "iteration 0 / 1500: loss 2362.198542\n",
            "iteration 100 / 1500: loss 5.445339\n",
            "iteration 200 / 1500: loss 5.047101\n",
            "iteration 300 / 1500: loss 4.207938\n",
            "iteration 400 / 1500: loss 5.046459\n",
            "iteration 500 / 1500: loss 6.096243\n",
            "iteration 600 / 1500: loss 5.421990\n",
            "iteration 700 / 1500: loss 4.752485\n",
            "iteration 800 / 1500: loss 5.149293\n",
            "iteration 900 / 1500: loss 5.931171\n",
            "iteration 1000 / 1500: loss 5.437573\n",
            "iteration 1100 / 1500: loss 5.109136\n",
            "iteration 1200 / 1500: loss 6.026149\n",
            "iteration 1300 / 1500: loss 6.074960\n",
            "iteration 1400 / 1500: loss 5.741605\n",
            "iteration 0 / 1500: loss 3106.421992\n",
            "iteration 100 / 1500: loss 8.495339\n",
            "iteration 200 / 1500: loss 6.788838\n",
            "iteration 300 / 1500: loss 7.619691\n",
            "iteration 400 / 1500: loss 8.745728\n",
            "iteration 500 / 1500: loss 6.990186\n",
            "iteration 600 / 1500: loss 8.713758\n",
            "iteration 700 / 1500: loss 8.342381\n",
            "iteration 800 / 1500: loss 8.044582\n",
            "iteration 900 / 1500: loss 8.219746\n",
            "iteration 1000 / 1500: loss 9.142914\n",
            "iteration 1100 / 1500: loss 8.277401\n",
            "iteration 1200 / 1500: loss 6.765216\n",
            "iteration 1300 / 1500: loss 8.347885\n",
            "iteration 1400 / 1500: loss 9.565434\n",
            "iteration 0 / 1500: loss 3846.526985\n",
            "iteration 100 / 1500: loss 14.772734\n",
            "iteration 200 / 1500: loss 12.949465\n",
            "iteration 300 / 1500: loss 13.241151\n",
            "iteration 400 / 1500: loss 15.664248\n",
            "iteration 500 / 1500: loss 14.432459\n",
            "iteration 600 / 1500: loss 15.228041\n",
            "iteration 700 / 1500: loss 12.988229\n",
            "iteration 800 / 1500: loss 12.941174\n",
            "iteration 900 / 1500: loss 14.994780\n",
            "iteration 1000 / 1500: loss 14.928620\n",
            "iteration 1100 / 1500: loss 14.581558\n",
            "iteration 1200 / 1500: loss 11.460614\n",
            "iteration 1300 / 1500: loss 12.740384\n",
            "iteration 1400 / 1500: loss 12.293452\n",
            "iteration 0 / 1500: loss 4617.038227\n",
            "iteration 100 / 1500: loss 27.362465\n",
            "iteration 200 / 1500: loss 28.087121\n",
            "iteration 300 / 1500: loss 29.594194\n",
            "iteration 400 / 1500: loss 28.189651\n",
            "iteration 500 / 1500: loss 30.060373\n",
            "iteration 600 / 1500: loss 30.854966\n",
            "iteration 700 / 1500: loss 29.677148\n",
            "iteration 800 / 1500: loss 26.681857\n",
            "iteration 900 / 1500: loss 28.604473\n",
            "iteration 1000 / 1500: loss 29.615065\n",
            "iteration 1100 / 1500: loss 27.386159\n",
            "iteration 1200 / 1500: loss 26.523457\n",
            "iteration 1300 / 1500: loss 28.066574\n",
            "iteration 1400 / 1500: loss 31.159870\n",
            "iteration 0 / 1500: loss 767.381431\n",
            "iteration 100 / 1500: loss inf\n",
            "iteration 200 / 1500: loss inf\n",
            "iteration 300 / 1500: loss inf\n",
            "iteration 400 / 1500: loss inf\n",
            "iteration 500 / 1500: loss inf\n",
            "iteration 600 / 1500: loss inf\n",
            "iteration 700 / 1500: loss inf\n",
            "iteration 800 / 1500: loss inf\n",
            "iteration 900 / 1500: loss inf\n",
            "iteration 1000 / 1500: loss inf\n",
            "iteration 1100 / 1500: loss inf\n",
            "iteration 1200 / 1500: loss inf\n",
            "iteration 1300 / 1500: loss inf\n",
            "iteration 1400 / 1500: loss inf\n",
            "iteration 0 / 1500: loss 1547.449910\n",
            "iteration 100 / 1500: loss inf\n",
            "iteration 200 / 1500: loss inf\n",
            "iteration 300 / 1500: loss inf\n",
            "iteration 400 / 1500: loss inf\n",
            "iteration 500 / 1500: loss inf\n",
            "iteration 600 / 1500: loss nan\n",
            "iteration 700 / 1500: loss nan\n",
            "iteration 800 / 1500: loss nan\n",
            "iteration 900 / 1500: loss nan\n",
            "iteration 1000 / 1500: loss nan\n",
            "iteration 1100 / 1500: loss nan\n",
            "iteration 1200 / 1500: loss nan\n",
            "iteration 1300 / 1500: loss nan\n",
            "iteration 1400 / 1500: loss nan\n",
            "iteration 0 / 1500: loss 2296.823490\n",
            "iteration 100 / 1500: loss inf\n",
            "iteration 200 / 1500: loss inf\n",
            "iteration 300 / 1500: loss inf\n",
            "iteration 400 / 1500: loss nan\n",
            "iteration 500 / 1500: loss nan\n",
            "iteration 600 / 1500: loss nan\n",
            "iteration 700 / 1500: loss nan\n",
            "iteration 800 / 1500: loss nan\n",
            "iteration 900 / 1500: loss nan\n",
            "iteration 1000 / 1500: loss nan\n",
            "iteration 1100 / 1500: loss nan\n",
            "iteration 1200 / 1500: loss nan\n",
            "iteration 1300 / 1500: loss nan\n",
            "iteration 1400 / 1500: loss nan\n",
            "iteration 0 / 1500: loss 3078.330030\n",
            "iteration 100 / 1500: loss inf\n",
            "iteration 200 / 1500: loss inf\n",
            "iteration 300 / 1500: loss inf\n",
            "iteration 400 / 1500: loss nan\n",
            "iteration 500 / 1500: loss nan\n",
            "iteration 600 / 1500: loss nan\n",
            "iteration 700 / 1500: loss nan\n",
            "iteration 800 / 1500: loss nan\n",
            "iteration 900 / 1500: loss nan\n",
            "iteration 1000 / 1500: loss nan\n",
            "iteration 1100 / 1500: loss nan\n",
            "iteration 1200 / 1500: loss nan\n",
            "iteration 1300 / 1500: loss nan\n",
            "iteration 1400 / 1500: loss nan\n",
            "iteration 0 / 1500: loss 3831.411113\n",
            "iteration 100 / 1500: loss inf\n",
            "iteration 200 / 1500: loss inf\n",
            "iteration 300 / 1500: loss nan\n",
            "iteration 400 / 1500: loss nan\n",
            "iteration 500 / 1500: loss nan\n",
            "iteration 600 / 1500: loss nan\n",
            "iteration 700 / 1500: loss nan\n",
            "iteration 800 / 1500: loss nan\n",
            "iteration 900 / 1500: loss nan\n",
            "iteration 1000 / 1500: loss nan\n",
            "iteration 1100 / 1500: loss nan\n",
            "iteration 1200 / 1500: loss nan\n",
            "iteration 1300 / 1500: loss nan\n",
            "iteration 1400 / 1500: loss nan\n",
            "iteration 0 / 1500: loss 4637.411608\n",
            "iteration 100 / 1500: loss inf\n",
            "iteration 200 / 1500: loss inf\n",
            "iteration 300 / 1500: loss nan\n",
            "iteration 400 / 1500: loss nan\n",
            "iteration 500 / 1500: loss nan\n",
            "iteration 600 / 1500: loss nan\n",
            "iteration 700 / 1500: loss nan\n",
            "iteration 800 / 1500: loss nan\n",
            "iteration 900 / 1500: loss nan\n",
            "iteration 1000 / 1500: loss nan\n",
            "iteration 1100 / 1500: loss nan\n",
            "iteration 1200 / 1500: loss nan\n",
            "iteration 1300 / 1500: loss nan\n",
            "iteration 1400 / 1500: loss nan\n",
            "lr 1.000000e-07 reg 2.500000e+04 train accuracy: 0.328571 val accuracy: 0.349000\n",
            "lr 1.000000e-07 reg 5.000000e+04 train accuracy: 0.309327 val accuracy: 0.324000\n",
            "lr 1.000000e-07 reg 7.500000e+04 train accuracy: 0.296796 val accuracy: 0.311000\n",
            "lr 1.000000e-07 reg 1.000000e+05 train accuracy: 0.287204 val accuracy: 0.299000\n",
            "lr 1.000000e-07 reg 1.250000e+05 train accuracy: 0.279796 val accuracy: 0.293000\n",
            "lr 1.000000e-07 reg 1.500000e+05 train accuracy: 0.280673 val accuracy: 0.290000\n",
            "lr 5.000000e-07 reg 2.500000e+04 train accuracy: 0.324776 val accuracy: 0.335000\n",
            "lr 5.000000e-07 reg 5.000000e+04 train accuracy: 0.314633 val accuracy: 0.325000\n",
            "lr 5.000000e-07 reg 7.500000e+04 train accuracy: 0.284633 val accuracy: 0.294000\n",
            "lr 5.000000e-07 reg 1.000000e+05 train accuracy: 0.286755 val accuracy: 0.292000\n",
            "lr 5.000000e-07 reg 1.250000e+05 train accuracy: 0.274102 val accuracy: 0.290000\n",
            "lr 5.000000e-07 reg 1.500000e+05 train accuracy: 0.265755 val accuracy: 0.276000\n",
            "lr 1.000000e-06 reg 2.500000e+04 train accuracy: 0.321000 val accuracy: 0.324000\n",
            "lr 1.000000e-06 reg 5.000000e+04 train accuracy: 0.303429 val accuracy: 0.326000\n",
            "lr 1.000000e-06 reg 7.500000e+04 train accuracy: 0.270857 val accuracy: 0.276000\n",
            "lr 1.000000e-06 reg 1.000000e+05 train accuracy: 0.276082 val accuracy: 0.292000\n",
            "lr 1.000000e-06 reg 1.250000e+05 train accuracy: 0.253612 val accuracy: 0.264000\n",
            "lr 1.000000e-06 reg 1.500000e+05 train accuracy: 0.261980 val accuracy: 0.267000\n",
            "lr 5.000000e-06 reg 2.500000e+04 train accuracy: 0.192347 val accuracy: 0.203000\n",
            "lr 5.000000e-06 reg 5.000000e+04 train accuracy: 0.149163 val accuracy: 0.158000\n",
            "lr 5.000000e-06 reg 7.500000e+04 train accuracy: 0.139061 val accuracy: 0.139000\n",
            "lr 5.000000e-06 reg 1.000000e+05 train accuracy: 0.094286 val accuracy: 0.108000\n",
            "lr 5.000000e-06 reg 1.250000e+05 train accuracy: 0.116837 val accuracy: 0.112000\n",
            "lr 5.000000e-06 reg 1.500000e+05 train accuracy: 0.121041 val accuracy: 0.127000\n",
            "lr 1.000000e-05 reg 2.500000e+04 train accuracy: 0.162633 val accuracy: 0.159000\n",
            "lr 1.000000e-05 reg 5.000000e+04 train accuracy: 0.100776 val accuracy: 0.096000\n",
            "lr 1.000000e-05 reg 7.500000e+04 train accuracy: 0.131265 val accuracy: 0.148000\n",
            "lr 1.000000e-05 reg 1.000000e+05 train accuracy: 0.068143 val accuracy: 0.065000\n",
            "lr 1.000000e-05 reg 1.250000e+05 train accuracy: 0.072857 val accuracy: 0.070000\n",
            "lr 1.000000e-05 reg 1.500000e+05 train accuracy: 0.100265 val accuracy: 0.087000\n",
            "lr 5.000000e-05 reg 2.500000e+04 train accuracy: 0.049490 val accuracy: 0.052000\n",
            "lr 5.000000e-05 reg 5.000000e+04 train accuracy: 0.100265 val accuracy: 0.087000\n",
            "lr 5.000000e-05 reg 7.500000e+04 train accuracy: 0.100265 val accuracy: 0.087000\n",
            "lr 5.000000e-05 reg 1.000000e+05 train accuracy: 0.100265 val accuracy: 0.087000\n",
            "lr 5.000000e-05 reg 1.250000e+05 train accuracy: 0.100265 val accuracy: 0.087000\n",
            "lr 5.000000e-05 reg 1.500000e+05 train accuracy: 0.100265 val accuracy: 0.087000\n",
            "best validation accuracy achieved during cross-validation: 0.349000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rY18wElRJ08i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5954f084-06b3-4f49-a4f9-197f6f868c61"
      },
      "source": [
        "# evaluate on test set\n",
        "# Evaluate the best softmax on test set\n",
        "y_test_pred = best_softmax_classifer.predict(X_test)\n",
        "test_accuracy = np.mean(y_test == y_test_pred)\n",
        "print('softmax on raw pixels final test set accuracy: %f' % (test_accuracy, ))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "softmax on raw pixels final test set accuracy: 0.341000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iwERfXwJ08l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "outputId": "2ccde0d0-357a-4fd4-b5ec-f0edb5cb7586"
      },
      "source": [
        "# Visualize the learned weights for each class\n",
        "w = best_softmax_classifer.W[:-1,:] # strip out the bias\n",
        "w = w.reshape(32, 32, 3, 10)\n",
        "\n",
        "w_min, w_max = np.min(w), np.max(w)\n",
        "\n",
        "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "for i in range(10):\n",
        "    plt.subplot(2, 5, i + 1)\n",
        "    \n",
        "    # Rescale the weights to be between 0 and 255\n",
        "    wimg = 255.0 * (w[:, :, :, i].squeeze() - w_min) / (w_max - w_min)\n",
        "    plt.imshow(wimg.astype('uint8'))\n",
        "    plt.axis('off')\n",
        "    plt.title(classes[i])"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7EFiDVPKejJy",
        "colab_type": "text"
      },
      "source": [
        "*Many thanks to Stanford CS231n for permission to use their materials!*"
      ]
    }
  ]
}
